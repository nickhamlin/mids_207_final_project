{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "\n",
    "def load_train_data():\n",
    "    with open('data/train.csv') as f:\n",
    "        features = f.next().rstrip().split(',')[1:]\n",
    "        data = np.loadtxt(f, delimiter=',')\n",
    "        X, Y = data[:,1:], data[:,:1]\n",
    "        return features, X, Y.flatten()\n",
    "\n",
    "def load_test_data():\n",
    "    with open('data/test.csv') as f:\n",
    "        features = f.next().rstrip().split(',')[1:]\n",
    "        return np.loadtxt(f, delimiter=',')\n",
    "\n",
    "features, X, Y = load_train_data()\n",
    "test_data = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Useful functions\n",
    "\n",
    "# Pairwise transform:\n",
    "# Divide each row in two parts, one for each person in the comparison and subtract the logs of them.\n",
    "# A +1 factor is used to have only non-negative logs.\n",
    "def trans(x):\n",
    "    return np.log(1 + x[:,:11]) - np.log(1 + x[:,11:] )\n",
    "\n",
    "# Rolling-hash on the features of a person\n",
    "def hash(a):\n",
    "    base = 100\n",
    "    res = 0\n",
    "    for i in range(len(a)):\n",
    "        res += base ** i * a[i]\n",
    "    return res\n",
    "\n",
    "# Creates an undirected graph where all the rows, which are comparisons, are represented by edges.\n",
    "def get_edges(x):\n",
    "    A = x[:,:11]\n",
    "    B = x[:,11:]\n",
    "\n",
    "    mapa = {}\n",
    "    tot = 0\n",
    "    edges = []\n",
    "    adj = {}\n",
    "    for i in range(len(A)):\n",
    "        a = hash(list(A[i]))\n",
    "        if a not in mapa:\n",
    "            mapa[a] = tot\n",
    "            adj[tot] = set()\n",
    "            tot += 1\n",
    "        b = hash(list(B[i]))\n",
    "        if b not in mapa:\n",
    "            mapa[b] = tot\n",
    "            adj[tot] = set()\n",
    "            tot += 1\n",
    "        edges.append((mapa[a], mapa[b]))\n",
    "        adj[mapa[a]].add(mapa[b])\n",
    "        adj[mapa[b]].add(mapa[a])\n",
    "    return edges, tot, adj\n",
    "\n",
    "# Given the probability predictions, print the output in the format Kaggle can accept.\n",
    "def generate_test_output(pred_probs):\n",
    "    with open(\"test_labeled.csv\", \"w\") as f:\n",
    "        f.write('Id,Choice\\n')\n",
    "        for i,prob in enumerate(pred_probs):\n",
    "            f.write(str(i+1)+','+str(0.6 if prob[1] == 0.5 else prob[1])+'\\n')\n",
    "            \n",
    "# Pairwise transform for simple numbers\n",
    "def subtractlogs(a, b):\n",
    "    return np.log(1 + a) - np.log(1 + b)\n",
    "\n",
    "# Given two sets of features, create a graph of their combination\n",
    "def create_graph(x1, x2):\n",
    "    x = np.concatenate((x1, x2))\n",
    "    edges, n, adj = get_edges(x)\n",
    "    ug = nx.Graph()\n",
    "    map(lambda i: ug.add_node(i), range(n))\n",
    "    map(lambda (a, b): ug.add_edge(a, b), edges)\n",
    "    return ug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an undirected graph of the combination of the train and test data\n",
    "ug = create_graph(trans(X), trans(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate several graph centrality measures\n",
    "pr = nx.pagerank(ug)\n",
    "degc = nx.degree_centrality(ug)\n",
    "close = nx.closeness_centrality(ug)\n",
    "load = nx.load_centrality(ug)\n",
    "bet = nx.betweenness_centrality(ug)\n",
    "ecc = nx.eccentricity(ug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def network_features(x1, x2):\n",
    "    x = np.concatenate((x1, x2))\n",
    "    edges, n, adj = get_edges(x)\n",
    "    features = []\n",
    "    for i in range(len(x)):\n",
    "        a = edges[i][0]\n",
    "        b = edges[i][1]\n",
    "        features.append([\n",
    "            subtractlogs(degc[a], degc[b]),\n",
    "            subtractlogs(close[a], close[b]),\n",
    "            subtractlogs(len(adj[a]), len(adj[b])),\n",
    "            subtractlogs(load[a], load[b]),\n",
    "            subtractlogs(bet[a], bet[b]),\n",
    "            subtractlogs(ecc[a], ecc[b]),\n",
    "            subtractlogs(pr[a], pr[b])\n",
    "        ])\n",
    "    return features[:len(x1)], features[len(x1):]\n",
    "\n",
    "x_feat, test_x_feat = network_features(trans(X), trans(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine the original features with the network features\n",
    "x = trans(X)\n",
    "test_x = trans(test_data)\n",
    "x_feat, test_x_feat = network_features(x, test_x)\n",
    "\n",
    "x = np.concatenate((x, x_feat), axis=1)\n",
    "test_x = np.concatenate((test_x, test_x_feat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For every feature, make a negative copy of it, so that there's a balance between all the cases were A < B and B > A.\n",
    "xx = []\n",
    "yy = []\n",
    "for i in range(len(Y)):\n",
    "    xx.append(x[i])\n",
    "    yy.append(Y[i])\n",
    "    xx.append(-x[i])\n",
    "    yy.append(1 - Y[i])\n",
    "\n",
    "# For every row, append the ratio following / followers as a new feature\n",
    "for i in range(len(xx)):\n",
    "    xx[i] = np.append(xx[i], xx[i][0] / (xx[i][1] + 1)) \n",
    "tx = []\n",
    "for i in range(len(test_x)):\n",
    "    tx.append(np.append(test_x[i], test_x[i][0] / (test_x[i][0] + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First classifier, Bagging + LR\n",
    "clf = BaggingClassifier(\n",
    "    LogisticRegression(C=1/.60),\n",
    "    max_samples=0.3, max_features=0.7, n_estimators=200, n_jobs=-1, random_state=3)\n",
    "clf.fit(xx, yy)\n",
    "proba1 = clf.predict_proba(tx)\n",
    "\n",
    "# Second classifier, Bagging + GBC\n",
    "clf = BaggingClassifier(\n",
    "    GradientBoostingClassifier(max_depth=2, max_features=.99, subsample=0.9),\n",
    "    max_samples=0.3, max_features=0.7, n_estimators=50, n_jobs=-1, random_state=1\n",
    ")\n",
    "clf.fit(xx, yy)\n",
    "proba2 = clf.predict_proba(tx)\n",
    "\n",
    "# Combine both results as a weigthed average.\n",
    "generate_test_output(proba1 * .72 + proba2 * .28)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
